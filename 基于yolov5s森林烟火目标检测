https://github.com/Philharmy-Wang/M4SFWD
基于改进YOLOv5s的森林烟火检测算法
https://pdf.hanspub.org/csa2024144_281543207.pdf

Published Online April 2024 in Hans. https://www.hanspub.org/journal/csa
https://doi.org/10.12677/csa.2024.144098
文章引用: 冯艳玲, 韩毓莹, 余智美, 朱珉慧, 朱雨荷, 孙庆华. 基于改进 YOLOv5s 的森林烟火检测算法[J]. 计算机科
学与应用, 2024, 14(4): 290-297. DOI: 10.12677/csa.2024.144098
原 YOLOv5 网络中，基础核心模块 C3 使用了以 ResNet 为核心算法的残差网络模块，可以使网络的学
习能力大大提高。但是传统的 ResNet 块只使用单一的残差连接来传递信息，这意味着网络可能无法有效地
捕获不同层次的特征。然而在森林火灾发生初期，火焰目标比较小而烟雾一般范围更大，实际情况还因不
同地形和天气又不同，目标的尺度大小不规律，原 YOLOv5 网络在森林火灾特征提取场景下存在精度不高



调整网络层和模块 🛠️
1. 增加卷积层
目的：增强模型的特征提取能力，捕获更丰富的图像信息。
做法：
在 backbone（特征提取部分）加入额外的卷积层。
例如，在某些阶段添加卷积块，提升深层特征的表达。
注意事项：
增加层数可能导致训练变慢，要合理控制深度。
需要重新调整学习率和训练策略。
2. 引入注意力机制（Attention Modules）
作用：让模型更关注图像中的关键区域，提升检测精度。
常用模块：
CBAM（Convolutional Block Attention Module）：
结合通道和空间注意力机制。
作用：增强重要通道和空间区域的特征。
SE（Squeeze-and-Excitation）块：
通过自适应调整通道权重，强化关键通道信息。
Implementation：
将注意力模块插入到 backbone 的某些层或特征融合部分。
3. 改进特征提取网络（Backbone）
替换或增强 backbone：
用更强的网络结构：如 ResNet、EfficientNet、MobileNet 等。
目的：提升特征表达能力，增强模型对复杂场景的适应性。
方法：
修改 YOLOv5 源码中的 backbone 定义，替换为新结构。
需要注意预训练权重的迁移。
4. 特征融合模块优化
引入或调整特征融合结构：
FPN（特征金字塔网络）：多尺度特征融合。
PAN（路径聚合网络）：增强不同尺度特征的交互。
目标：
改善不同尺度目标的检测能力。
提升对小目标和大目标的识别效果。
示意图：调整网络层和模块的流程🖼️
操作	具体措施	作用
添加卷积层	在 backbone 增加深层卷积	提升特征表达
引入注意力模块	CBAM、SE	聚焦重要区域
替换 backbone	使用 ResNet、EfficientNet	提升特征质量
优化特征融合	改进 FPN、PAN	多尺度信息更充分
小贴士💡
逐步试验：每次只加入一种模块或调整一层，观察效果。
验证效果：用验证集检测改动带来的提升，避免过拟合。
计算资源：复杂模块会增加计算负担，要结合实际条件。


引入注意力机制（Attention Modules）💡
作用
让模型更关注图像中的关键区域，提升检测的准确性。
增强重要特征，抑制无关或干扰信息。
提高模型对复杂环境（如夜间、烟雾、火焰）中微弱信号的敏感度。
常用的注意力模块
模块名称	核心思想	作用
CBAM（Convolutional Block Attention Module）	结合通道和空间注意力	让模型同时关注重要的通道和空间位置
SE（Squeeze-and-Excitation）块	只关注通道注意力	自适应调整每个通道的重要性
1. CBAM（Convolutional Block Attention Module）🧠
核心机制
通道注意力：通过全局平均池化和最大池化，获得每个通道的重要性，经过全连接层生成通道权重。
空间注意力：在通道注意力之后，将特征图沿通道维度合并（平均和最大池化），得到空间位置的重要性图。
作用
增强关键通道和空间区域的特征表达，提升模型对目标的敏感度。
插入位置
可以插入到 backbone 的某些层或特征融合部分，增强特征表示。
2. SE（Squeeze-and-Excitation）块🔄
核心机制
Squeeze（压缩）：对每个通道进行全局平均池化，获得通道描述符。
Excitation（激励）：通过两个全连接层，学习每个通道的重要性权重。
重标定（Reweighting）：用学习到的权重对原始特征进行调整。
作用
自适应强化关键通道，抑制无用信息，提高特征表达质量。
插入位置
通常在 backbone 中的卷积块后面，增强特征表达。

3. 实现步骤（以 CBAM 为例）
1. 定义注意力模块
# 具体的通道和空间注意力实现略（可参考开源代码）
CBAM.py
2.集成到YOLOv5的模型
修改YOLOv5模型结构
目标：在特征提取部分（如C3模块）加入CBAM
方法：
找到models/common.py中的C3模块定义
在C3模块中加入CBAM
C3CBAM.py
替换原有的C3模块为C3CBAM。

3. 训练和调优
观察模型性能变化，调整注意力模块的位置和参数。
使用少量夜间和烟雾环境数据进行微调
保持模型推理速度，建议使用GPU
你可以在train.py中加载你的数据集，按照常规流程训练





