一.关于数据集补充
1.补充场景后，同一个模型不改超参数和骨干的情况下，整体指标下降，这个时候需要改一下超参数么？还是说是数据集质量不行
  怎么判断这个数据集是否质量高 是否可用
2.另一个数据补充的办法（在既存图像上等比例分割后进行筛选和标注），精度提高但是召回率低只有74且途中发生了一点点过拟合现象导致Map：0.5只有82左右，这种情况
    2.1如何解决过拟合，调参么？
    2.2怎么平衡精度和召回率

二.关于注意力机制
1.为什么引入注意力机制后整体的map并没有上涨反而小幅下降？是因为数据集过于简单么，用不上注意力机制，引入注意力机制反而学习了那些噪音？

三.关于损失函数
1.尝试过用eiou来替代ciou ，效果不好，原因推测为，eiou惩罚机制更加严格，不太适合火和烟这种形状不固定的场景。
.EIOU的惩戒机制更加严格，这就导致低置信度的部分被惩戒掉，从而召回率降低，但是降低置信度后依然没有很大效果

四.关于调参
1.有没有更好的办法在调超参数后能快速且性价比高的验证参数有效性？而不是每次都训练
2.想利用optuna进行自动化调参找到最佳组合，实验次数给多少次呢？30次 每次训练30个轮次这个参数是否可以。或者说是否可以每次30个轮次但只训练十次呢，在这十次里找最优参数这样可以最多就训练300轮

五.关于训练策略
1.基于赵婕那版的best。探索了几次训练策略（比如在这基础上冷冻层数后接着训练）。但都很震荡，有没有好的训练策略？

六.关于骨干调整
1.注意力机制和骨干到底什么时候替换比较好呢？是在数据集稳定后改还是什么时候改性价比比较高？